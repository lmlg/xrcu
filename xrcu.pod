=encoding utf-8

=head1 NAME

XRCU is a library that provides efficient lock-less synchronization for read-mostly tasks and structures

=head1 ABOUT THIS DOCUMENT

This file is meant to document the XRCU library, including internal details
and the rationale behind the decisions taken.

This document assumes that the reader is at least somewhat familiar with such
concepts as multi-threading, lock-free algorithms and data structures, and
read-copy-update (RCU).

=head1 ABOUT LOCK FREE ALGORITHMS AND STRUCTURES

The term I<lock free> is used to refer to several different things depending
on the author, but the basic idea is that an algorithm or structure is lock
free if multiple threads can operate on it without the end result being
dependent on said threads' scheduling. That is, it doesn't matter if the
involved threads are suspended or preempted; progress is guaranteed.

The usually mentioned advantage of lock freedom is performance. When you are
using lock free algorithms, you naturally avoid using things like mutexes,
which can have a non-negligible performance impact. On the other hand, other
people point out that lock free algorithms are typically harder to understand,
that debugging is notoriously difficult, and that the benefits generally do
not compensate for these complexities.

The reason why this library was developed is to give other programmers another
option when designing high performant, low latency systems. I do not claim that
lock freedom is a silver bullet when it comes to making programs faster. On the
other hand, it's also hard to argue that lock contention tends to be a real
bottleneck, and several projects have moved towards lock free structures given
the performance benefits they bring (see for example, many kernels).

=head1 ABOUT RCU

There is a big problem with using lock free algorithms in programming languages
that feature manual memory management, and it has to do with reclamation. Since
lock freedom implies that multiple threads may operate on a given structure
concurrently, it is possible to find ourselves in a situation in which a thread
is reading some data, while another one is modifying or deleting that same
piece of data, potentially freeing the memory associated to it.

As such, lock freedom isn't feasible as in languages like C and C++. We need
an additional subsystem that allows us to synchronize reclamation without using
heavyweight methods like mutexes (we are developing a lock-free library, after
all).

This is where RCU comes in. RCU, short for read-copy-update, is a mechanism
that allows multiple threads to I<read> from memory, while postponing
reclamations until it is safe to do so (i.e: until no readers are operating
on said memory).

There are several different ways to implement RCU, and the one chosen in this
library will be detailed later. For now, it's important to notice that RCU
typically makes reading from shared memory a very cheap operation, while
imposing more overhead on updates. Thus, it's more suited for tasks in which
reads are more frequent than modifications.

It should be noted that RCU is not the only way to manage memory reclamations
in a multi-threaded environment, but as its name implies, XRCU chose it because
it was deemed the best option. Since lock-free structures rely on RCU to work
properly, we'll describe the RCU interface that this library exposes first.

=head2 API design

All public interfaces (functions, types, methods, etc) reside in the namespace
C<xrcu>. It's the explicit intent of the author to mantain compatibility with
every interface that was ever exposed. Any breaking changes should be done in
different interfaces (either by adding new functions, or by overloading).

The implementation of some template types require additional, internal details,
and those usually reside in a namespace appropriately named C<detail> (Said
namespace resides in C<xrcu>). It should go without saying that users should
I<not> rely on those internal details, and that the author may freely break
compatibility against such details.

XRCU uses some thread-specific data in order to function properly. There may
be some systems that have issues when dynamically loading libraries that use
thread-specific data (I believe Windows Vista was among them). Consult with
your working environment's manual to verify that if you notice any problem.

Finally, it should be mentioned that XRCU requires no initialization/cleanup
at a library level to function properly. Once the library is installed, you
can freely use its API without any further action needed.

=head2 RCU API

  #include <xrcu/xrcu.hpp>

The following section documents the RCU API that is exposed in XRCU. It's used
internally quite a bit by other parts of the library, yet it's very useful by
itself when implementing other concurrent algorithms or data structures.

=head3 RCU critical section management

RCU is based on the concept of I<critical sections>, code fragments that
execute under the guarantee that no reclamation can take place. This allows
the user to safely read from shared memory, knowing that it will be valid
during the critical section. Writes have to be synchronized independently
of RCU, however.

Naturally, RCU critical sections don't prevent I<all> memory reclamation,
they only affect destruction of objects that are derived from a type defined
in XRCU, called C<finalizable>. If you wish to use the RCU API, all you need to
do is make your types derive from C<finalizable> and you'll be set. Any other
memory management function, like C<malloc> and friends is unaffected by RCU as
implemented in this library.

Critical sections are managed through the following API:

=over 4

=item void enter_cs (void);

Starts a critical section for the calling thread. Critical sections can be
safely nested without problem. As long as we are in a critical section,
C<finalizable> objects cannot be reclaimed.

=item void exit_cs (void);

Ends a critical section. This is generally called after the calling thread
is done reading from shared memory, and wants to signal that reclamations
should be re-allowed. The effects of calling C<exit_cs> when the calling thread
is not in a critical section are undefined.

=item bool in_cs (void);

Returns true if the calling thread is in a critical section; false otherwise.

=item bool sync (void);

Waits until all threads are outside a critical section, and returns true
afterwards. If a deadlock is detected (because the calling thread is in a
critical section, for example), this function returns false immediately
without waiting.

Note that this call is affected by I<ongoing> critical sections. If a thread
enters a new one after another thread has already called C<sync>, the blocked
thread will not wait for it.

=item struct cs_guard

This type is defined such that its constructor calls C<enter_cs>, and its
destructor calls C<exit_cs>; it has no internal state. As its name implies,
it's useful as a guard to manage entering and exiting a critical section in
a way that is exception safe. A few types in this library are derived from
C<cs_guard>, such as iterators, since they need to examine potentially many
elements from a container without their memory being reclaimed.

=back

=head3 RCU finalizable objects

As it was mentioned before, XRCU defines a type called C<finalizable> that
is specifically designed to make its destruction safe (i.e: Only once all
threads are outside a critical section). This type defines the following
interface:

  struct finalizable
    {
      virtual void safe_destroy () {}
      virtual ~finalizable () {}
    };

Under most circumstances, it's enough for a user-defined type to derive from
C<finalizable> and leave it at that. However, the above 2 methods are provided
as virtual for customization's sake. When a C<finalizable> object is reclaimed
by the RCU subsystem, it will call the C<safe_destroy> method. The default
implementation simply calls the object's destructor and frees the memory
associated to it. If, for whatever reason, a user wants to override this
behaviour, they may do so by extending either of those methods.

In addition, the following API is available when dealing with finalizables:

=over 4

=item void finalize (finalizable *F);

Adds the object F to the calling thread's list of pending finalizable objects.
Each thread has a limit of C<finalizables>, and keeps count on them. Once they
reach C<XRCU_MAX_FINS>, they are scheduled for reclamation, and will be
collected once it's safe to do so.

Only a single call to C<finalize> is allowed on a particular object. If this
function is called more than once on the same object (Either by the same
thread, or another), the behaviour is undefined.

=item bool flush_finalizers (void);

Schedule all the calling thread's accumulated C<finalizable> objects for
reclamation immediately. Returns true if successful, false if a deadlock was
detected. Note that this call may block until all threads are outside a
critical section (Much as a call to C<sync> would).

=back

=head3 Implementation details

There are many ways to implement RCU. In this library, it was fundamental that
RCU be implemented in a portable, simple way, even if it meant slightly more
overhead. As such, things like signals and OS-specific syscalls were out.

In the end, for XRCU, we decided to use a global registry that uses a stamp
to monitor which threads are in critical sections. By using C++ thread_local
objects, we avoid the need for explicit registration, so that only when a
thread first uses the RCU API, it is added automatically to the global
registry.

In order to enter a critical section, all a thread has to do is read a global
counter, usually bump it by some small value, and then store that value with
release semantics in its thread-specific data. Exiting a critical section is
almost entirely symmetric (We decrement the thread-specific value), but with a
small caveat that will be explained below.

When an object is finalized, it's prepended to a singly-linked list that is
also kept in thread-specific storage. Once a certain number of them have been
accumulated (specified by the constant XRCU_MAX_FINS), they are scheduled to
be reclaimed. However, if the calling thread is inside a critical section at
that point, a special flag is set instead, that tells the thread to immediately
flush the C<finalizable> objects it has once it's outside the critical section.

In this implementation, the most expensive operation is undoubtedly C<sync>.
It works by locking the global registry, then checking if any thread is in a
critical section, and sleeping for short periods of time in case there are.
The overhead associated to C<sync> is the main reason why critical sections
should be short, and also the why C<finalizable> objects are accumulated
instead of being reclaimed right away.

=head2 Stacks

  #include <xrcu/stack.hpp>

Stacks are the simplest of the lock-free data structures: They represent a
basic LIFO stack on which you can push and pop items, one at a time. Although
their functionality is a bit more limited than other structures, they are still
very useful to implement things like atomic free lists.

In XRCU, stacks meet the requirements for the C++ concept of I<Container>.

=head3 Stack API

Stacks are templated types, that can be instantiated with a type T:

  template <class T>
  struct stack
    {
    };

The following describes the public interface for C<stack<TE<gt>>

=over 4

=item stack ();

Default constructor. Initializes a stack to empty.

=item template <class Integer> stack (Integer n, T value);

Initializes a stack to contain C<n> times C<value>.

=item template <class Iter> stack (Iter first, Iter last);

Initializes a stack to the range [C<first>, C<last>)

=item stack (std::initializer_list<T> lst);

Initializes a stack to hold the values in C<lst>

=item stack (const stack<T>& other);

Copy constructor. Initializes a stack to hold the values in C<other>.

=item stack (stack<T>&& other);

Move constructor. Takes ownership of the values in C<other>.

=item void push (const T& value);

Pushes C<value> to the top of the stack.

=item void emplace (T&& value);

Same as C<push>, only it constructs a new item by moving instead of copying.

=item T pop ();

Removes the item at the top of the stack, and returns the value associated.
If the stack is empty, it throws an exception of type C<std::runtime_error>.

=item T top ();

Fetches the current value at the top of the stack. If it's empty, it throws an
exception of the type C<std::runtime_error>.

=item size_type size () const;

Returns the current size of the stack.

=item size_type max_size () const;

Returns the maximum allowed size for the stack.

=item bool empty () const;

Returns true if the stack is empty (equivalent to C<size () == 0>).

=item void swap (stack<T>& other);

Swaps the contents of the stack with C<other>, but only if C<other> is not the
same object.

=item stack<T>& operator= (const stack<T>& other);

Assigns the contents of C<other> to the stack and returns C<*this>.

=item stack<T>& operator= (stack<T>&& other);

Move assignment. Takes ownership of the elements in C<other>.

=item bool operator== (const stack<T>& other) const;

Compares the elements of the stack with the ones in C<other>. Returns true
if they are all equal.

=item bool operator!= (const stack<T>& other) const;

Compares the elements of the stack with the ones in C<other>. Returns true
if any two of them are not equal.

=item bool operator<  (const stack<T>& other) const;

=item bool operator>  (const stack<T>& other) const;

=item bool operator<= (const stack<T>& other) const;

=item bool operator>= (const stack<T>& other) const;

Lexicographically compares the elements of the stack with the ones in C<other>,
in a way that is equivalent to calling C<std::lexicographical_compare>.

=item void clear ();

Removes every element from the stack.

=item template <class T1, class T2> void assign (T1 x, T2 y);

Assigns to the stack the elements described by (x, y). They could be an
iterator range, o a pair of (integer, value), as is the case with the stack's
constructor.

=item void assign (std::initializer_list<T> lst);

Assigns to the stack the items in C<lst>.

=back

Stacks also define iterator types that can be used to traverse it, even while
modifications are taking place. Unlike other cotainer types, no operation
performed on a stack (other than destruction) invalidates its iterators.

A stack iterator allows the user to get a reference to a particular item in the
stack, so that modifications are possible. However, keep in mind that the
iterator itself does not provide any way to synchronize writes, and so the user
must take care of that.

A stack's iterator is defined as such:

  template <class T>
  struct stack
    {
      struct iterator
        {
        };

      struct const_iterator
        {
        };
    };

In C++'s parlance, a stack iterator is a I<forward> iterator, and it may be
used in any function that accepts them.

An iterator is a C<cs_guard>, which means that an implicit critical section
is entered when one is created, and is extended until its destruction. As such,
no finalizable objects will be reclaimed during its lifetime.

The public interface for both iterator's and const_iterator's is identical,
except that the former yields a mutable object when dereferenced while the
latter does not. The following section documents said interfaces:

=over 4

=item iterator ();

Default constructor. Leaves the iterator initialized in an invalid state.
Dereferencing or incrementing this iterator has undefined behavior.

=item iterator (const iterator& other);

Copy constructor. Initializes the iterator to be equal to C<other>.

=item T& operator* ();

For an iterator, returns a reference to the iterator's underlying object.

=item T operator* () const;

For a const_iterator, returns a copy of the iterator's underlying object.

=item iterator& operator++ ();

Pre-increment operator. Moves the iterator forward, and returns itself. If the
iterator was at the end of the stack, the results are undefined.

=item iterator operator++ (int);

Post-increment operator. Moves the iterator forward, and returns an iterator
equal to what it was before incrementing. If the iterator was at the end of
the stack, the results are undefined.

=item bool operator== (const iterator& other);

=item bool operator!= (const iterator& other);

Tests for iterator (in)equality.

=back

In order to get iterators for a particular stack, users may call any of the
following methods on a stack:

=over 4

=item iterator begin ();

=item const_iterator cbegin () const;

Return an iterator to the first element of the stack.

=item iterator end ();

=item const_iterator cend () const;

Returns an iterator one past the last element of the stack.

=back

Given the above, a stack may be traversed using C++'s range-based for loop:

  stack<T> my_stack;
  ...
  for (T& x : my_stack)
    ...;

  for (const T& x : my_stack)
    ...;

